Title:
Deep Transfer in Reinforcement Learning by Language Grounding
Abstract: In this paper, we explore the utilization of natural language to drive
transfer for reinforcement learning (RL). Despite the wide-spread application
of deep RL techniques, learning generalized policy representations that work
across domains remains a challenging problem. We demonstrate that textual
descriptions of environments provide a compact intermediate channel to
facilitate effective policy transfer. We employ a model-based RL approach
consisting of a differentiable planning module, a model-free component and a
factorized representation to effectively utilize entity descriptions. Our model
outperforms prior work on both transfer and multi-task scenarios in a variety
of different environments.
